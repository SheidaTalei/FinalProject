{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SheidaTalei_BirchVsTFIDF_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPft5I7BzeyHPh+Grysm7lw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SheidaTalei/FinalProject/blob/main/SheidaTalei_BirchVsTFIDF_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhX-E7OQ-0ee"
      },
      "source": [
        "#SUBJECT: Birch Vs TF-IDF\r\n",
        "###AUTHOR: Sheida Talei"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJA4uBQl-5Rh",
        "outputId": "b264b7d3-efda-4f70-d4ef-2c6c8cee383d"
      },
      "source": [
        "import os, sys\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "nb_path = '/content/notebooks'\r\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\r\n",
        "sys.path.insert(0,nb_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sLcie3r_G9l"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.cluster import Birch\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7HIiiJK_w2a"
      },
      "source": [
        "\r\n",
        " "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJtdmnVB_G7i"
      },
      "source": [
        "#------------------------------------------Empty Rows Removal----------------------------------------------------------------\r\n",
        "# This function Will: 1- Remove all empty rows from csv file 2- Save data to the same csv\r\n",
        "def removeEmptyRows(fileName):\r\n",
        "    df = pd.read_csv(fileName, encoding='utf-8-sig')\r\n",
        "    df = df.dropna(subset=['text'], how='all', axis=0) \r\n",
        "    df.to_csv(fileName, header=True, encoding='utf-8-sig',  index=False)\r\n",
        "    \r\n",
        "    return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYIh4WaJ_G5M"
      },
      "source": [
        "\r\n",
        "X_and_Y = removeEmptyRows ('/content/drive/MyDrive/Final/train_temp.csv')\r\n",
        "Y= X_and_Y.Label\r\n",
        "X = X_and_Y.text"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irT-uPOX_cYy"
      },
      "source": [
        "#--------------------------------------------------Loading StopWords ------------------------------------------\r\n",
        "#Source of file: https://sites.google.com/site/kevinbouge/stopwords-lists\r\n",
        "def getStopWord ():\r\n",
        "    try:\r\n",
        "        file = open('/content/drive/MyDrive/Final/stopwords_fa.txt', 'r', encoding='utf-8-sig')\r\n",
        "        file_readed = file.read()\r\n",
        "    \r\n",
        "    finally:\r\n",
        "        file.close()\r\n",
        "        \r\n",
        "    stopWord_Set = set(file_readed.split())\r\n",
        "    return stopWord_Set\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0xw44m5_eHb"
      },
      "source": [
        "persian_stop_word = list(getStopWord())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gykaf0Hf_eFD"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words= persian_stop_word ,  max_features = 2000 ) \r\n",
        "X_train_vector  = vectorizer.fit_transform(X)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPk4Vfx7_eAj"
      },
      "source": [
        "#The branching_factor defines the number of sub-clusters and threshold sets the limit between the sample and sub-cluster.\r\n",
        "#Balanced Iterative Reducing and Clustering using Hierarchies, or BIRCH for short, deals with large datasets by first generating a more compact summary that retains as \r\n",
        "#much distribution information as possible, and then clustering the data summary instead of the original dataset.\r\n",
        "#Source: https://towardsdatascience.com/machine-learning-birch-clustering-algorithm-clearly-explained-fb9838cbeed9\r\n",
        "k= 3\r\n",
        "brc = Birch(branching_factor=50, n_clusters=k, threshold=0.1, compute_labels=True)\r\n",
        "brc.fit(X_train_vector)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ytDVTbuCWuR"
      },
      "source": [
        "clusters = brc.predict(X_train_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7Dug4HxCgfH"
      },
      "source": [
        "print (\"Clusters: \")\r\n",
        "print(clusters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6DxDolSCjq-"
      },
      "source": [
        "labels = brc.labels_\r\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXOwhRhSJUap"
      },
      "source": [
        "#source:https://ai.intelligentonlinetools.com/ml/tag/text-clustering/\r\n",
        "silhouette_score = metrics.silhouette_score(X_train_vector, labels, metric='euclidean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80I04JwNJ9ze"
      },
      "source": [
        "print (\"Silhouette_score: \",silhouette_score )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj01xE-1Jca8"
      },
      "source": [
        "SSE = []\r\n",
        "for cluster in range(1,50):\r\n",
        "    brc = Birch(branching_factor=50, n_clusters=cluster, threshold=0.1, compute_labels=True)\r\n",
        "    rc.fit(X_train_vector)\r\n",
        "    labels = brc.labels_\r\n",
        "    SSE.append(metrics.silhouette_score(X_train_vector, labels, metric='euclidean'))\r\n",
        "    print (cluster)\r\n",
        "\r\n",
        "# converting the results into a dataframe and plotting them\r\n",
        "frame = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})\r\n",
        "plt.figure(figsize=(12,6))\r\n",
        "plt.plot(frame['Cluster'], frame['SSE'], marker='o')\r\n",
        "plt.xlabel('Number of clusters')\r\n",
        "plt.ylabel('Silhouette_score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvZsBOLdK74H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}