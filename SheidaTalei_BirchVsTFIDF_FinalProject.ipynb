{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SheidaTalei_BirchVsTFIDF_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQWpg0q03554FmdHDkDquU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SheidaTalei/FinalProject/blob/main/SheidaTalei_BirchVsTFIDF_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhX-E7OQ-0ee"
      },
      "source": [
        "#SUBJECT: Birch Vs TF-IDF\r\n",
        "###AUTHOR: Sheida Talei"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "aJA4uBQl-5Rh",
        "outputId": "4be3a687-f46e-4caa-f1df-2df40e85952c"
      },
      "source": [
        "import os, sys\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "nb_path = '/content/notebooks'\r\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\r\n",
        "sys.path.insert(0,nb_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-01a0301fcd81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnb_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/notebooks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/My Drive/Colab Notebooks' -> '/content/notebooks'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sLcie3r_G9l"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.cluster import Birch\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7HIiiJK_w2a"
      },
      "source": [
        "\r\n",
        " "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJtdmnVB_G7i"
      },
      "source": [
        "#------------------------------------------Empty Rows Removal----------------------------------------------------------------\r\n",
        "# This function Will: 1- Remove all empty rows from csv file 2- Save data to the same csv\r\n",
        "def removeEmptyRows(fileName):\r\n",
        "    df = pd.read_csv(fileName, encoding='utf-8-sig')\r\n",
        "    df = df.dropna(subset=['text'], how='all', axis=0) \r\n",
        "    df.to_csv(fileName, header=True, encoding='utf-8-sig',  index=False)\r\n",
        "    \r\n",
        "    return df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYIh4WaJ_G5M"
      },
      "source": [
        "\r\n",
        "X_and_Y = removeEmptyRows ('/content/drive/MyDrive/Final/train_temp.csv')\r\n",
        "Y= X_and_Y.Label\r\n",
        "X = X_and_Y.text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irT-uPOX_cYy"
      },
      "source": [
        "#--------------------------------------------------Loading StopWords ------------------------------------------\r\n",
        "#Source of file: https://sites.google.com/site/kevinbouge/stopwords-lists\r\n",
        "def getStopWord ():\r\n",
        "    try:\r\n",
        "        file = open('/content/drive/MyDrive/Final/stopwords_fa.txt', 'r', encoding='utf-8-sig')\r\n",
        "        file_readed = file.read()\r\n",
        "    \r\n",
        "    finally:\r\n",
        "        file.close()\r\n",
        "        \r\n",
        "    stopWord_Set = set(file_readed.split())\r\n",
        "    return stopWord_Set\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0xw44m5_eHb"
      },
      "source": [
        "persian_stop_word = list(getStopWord())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gykaf0Hf_eFD"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words= persian_stop_word ,  max_features = 2000 ) \r\n",
        "X_train_vector  = vectorizer.fit_transform(X)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPk4Vfx7_eAj",
        "outputId": "e6bce5f5-3a45-456b-d78b-4942a955d804"
      },
      "source": [
        "#The branching_factor defines the number of sub-clusters and threshold sets the limit between the sample and sub-cluster.\r\n",
        "#Balanced Iterative Reducing and Clustering using Hierarchies, or BIRCH for short, deals with large datasets by first generating a more compact summary that retains as \r\n",
        "#much distribution information as possible, and then clustering the data summary instead of the original dataset.\r\n",
        "#Source: https://towardsdatascience.com/machine-learning-birch-clustering-algorithm-clearly-explained-fb9838cbeed9\r\n",
        "k= 5\r\n",
        "brc = Birch(branching_factor=5, n_clusters=k, threshold=0.85, compute_labels=True)\r\n",
        "brc.fit(X_train_vector)\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Birch(branching_factor=5, compute_labels=True, copy=True, n_clusters=5,\n",
              "      threshold=0.85)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ytDVTbuCWuR"
      },
      "source": [
        "clusters = brc.predict(X_train_vector)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7Dug4HxCgfH",
        "outputId": "23fae11c-60ee-4cda-be99-ba02de26c249"
      },
      "source": [
        "print (\"Clusters: \")\r\n",
        "print(clusters)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clusters: \n",
            "[0 1 0 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6DxDolSCjq-",
        "outputId": "13c0cd64-8e07-4e16-8abc-09242ce33dd7"
      },
      "source": [
        "labels = brc.labels_\r\n",
        "print(labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXOwhRhSJUap"
      },
      "source": [
        "#source:https://ai.intelligentonlinetools.com/ml/tag/text-clustering/\r\n",
        "silhouette_score = metrics.silhouette_score(X_train_vector, labels, metric='euclidean')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80I04JwNJ9ze",
        "outputId": "9204d03e-5a75-44e7-d32d-1ad3795cee59"
      },
      "source": [
        "print (\"Silhouette_score: \",silhouette_score )\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Silhouette_score:  0.0012493005980760581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj01xE-1Jca8"
      },
      "source": [
        "SSE = []\r\n",
        "for cluster in range(1,50):\r\n",
        "    brc = Birch(branching_factor=5, n_clusters=cluster, threshold=0.85, compute_labels=True)\r\n",
        "    brc.fit(X_train_vector)\r\n",
        "    labels = brc.labels_\r\n",
        "    SSE.append(metrics.silhouette_score(X_train_vector, labels, metric='euclidean'))\r\n",
        "    print (cluster)\r\n",
        "\r\n",
        "# converting the results into a dataframe and plotting them\r\n",
        "frame = pd.DataFrame({'Cluster':range(1,50), 'SSE':SSE})\r\n",
        "plt.figure(figsize=(12,6))\r\n",
        "plt.plot(frame['Cluster'], frame['SSE'], marker='o')\r\n",
        "plt.xlabel('Number of clusters')\r\n",
        "plt.ylabel('Silhouette_score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvZsBOLdK74H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}