{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SheidaTalei_XGboost_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SheidaTalei/FinalProject/blob/main/SheidaTalei_XGboost_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-7Dg8FznNtn"
      },
      "source": [
        "# SUBJECT: XGBoost\n",
        "### AUTHOR: Sheida Talei"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVR8uEhanWBa",
        "outputId": "17c323bf-3ff6-4749-8bb6-f5434f8ab517"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T90q4MMMnNto"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#Convert a collection of raw documents to a matrix of TF-IDF features.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import regex\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import re\n",
        "import string\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yZo9c80nfxp"
      },
      "source": [
        "#------------------------------------------Empty Rows Removal----------------------------------------------------------------\n",
        "# This function Will: 1- Remove all empty rows from csv file 2- Save data to the same csv\n",
        "def removeEmptyRows(fileName):\n",
        "    df = pd.read_csv(fileName, encoding='utf-8-sig')\n",
        "    df = df.dropna(subset=['text'], how='all', axis=0) \n",
        "    df.to_csv(fileName, header=True, encoding='utf-8-sig',  index=False)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXh7fE87BEtc"
      },
      "source": [
        "# df1= removeEmptyRows ('/content/drive/MyDrive/Final/Prepared_Data_1_Labeled.csv')\r\n",
        "# df2 =  removeEmptyRows ('/content/drive/MyDrive/Final/Prepared_train_Data_test#1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1XZmgR3XrYA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3NRXWZvnfna"
      },
      "source": [
        "# X_and_Y =pd.concat([df1, df2], ignore_index=True, names=['tweeter_handle', 'text', 'Label', 'statues_count' ])\n",
        "X_and_Y = removeEmptyRows ('/content/drive/MyDrive/Final/train_temp.csv')\n",
        "\n",
        "Y= X_and_Y.Label\n",
        "X = X_and_Y.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XHOL2Vbne-L"
      },
      "source": [
        "# X_and_Y_test = removeEmptyRows('/content/drive/MyDrive/Final/Prepared_test_Data_test#1.csv')\n",
        "X_and_Y_test = removeEmptyRows('/content/drive/MyDrive/Final/test_temp.csv')\n",
        "Y_test= X_and_Y_test.Label\n",
        "X_test = X_and_Y_test.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FHEGCPdoRAT"
      },
      "source": [
        "#--------------------------------------------------Loading StopWords ------------------------------------------\n",
        "#Source of file: https://sites.google.com/site/kevinbouge/stopwords-lists\n",
        "def getStopWord ():\n",
        "    try:\n",
        "        file = open('/content/drive/MyDrive/Final/stopwords_fa.txt', 'r', encoding='utf-8-sig')\n",
        "        file_readed = file.read()\n",
        "    \n",
        "    finally:\n",
        "        file.close()\n",
        "        \n",
        "    stopWord_Set = set(file_readed.split())\n",
        "    return stopWord_Set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNMIQejWoQ2y"
      },
      "source": [
        "persian_stop_word = list(getStopWord())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_Sh7GyWnNto"
      },
      "source": [
        "count_0 = 0\n",
        "count_1 = 0\n",
        "\n",
        "for i in Y:\n",
        "    if (i==0):\n",
        "        count_0 = count_0+1\n",
        "    else:\n",
        "        count_1 = count_1 + 1\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdbvkviu3ZLA",
        "outputId": "b1737573-01be-464d-8585-127d0ec82fdb"
      },
      "source": [
        "print(count_0)\r\n",
        "print(count_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23658\n",
            "24624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dcX3iJa3xd6"
      },
      "source": [
        "# import seaborn as sns\r\n",
        "\r\n",
        "# sns.countplot(x='Label', data=X_and_Y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaoDwWQ1nNtp"
      },
      "source": [
        "#source: https://xgboost.readthedocs.io/en/latest/parameter.html\n",
        "\n",
        "\n",
        "XGB_classifier = XGBClassifier(scale_pos_weight = count_1/count_0, n_estimators=500 , max_depth=8 , subsample=0.8 , eta = 0.1, verbosity=1 )\n",
        "\n",
        "# scale_pos_weight = 2237/7713\n",
        "\n",
        "#Source: https://stackoverflow.com/questions/44066264/how-to-choose-parameters-in-tfidfvectorizer-in-sklearn-during-unsupervised-clust\n",
        "\n",
        "\n",
        "\n",
        "vectorizer =  TfidfVectorizer(stop_words=persian_stop_word ,  max_features=2000 )\n",
        "X_train  = vectorizer.fit_transform(X)\n",
        "\n",
        "# pipeline = Pipeline([\n",
        "#     ('tfidf', TfidfVectorizer(stop_words=persian_stop_word )),\n",
        "#     ('clf',XGB_classifier),\n",
        "# ])\n",
        "# parameters = {\n",
        "#     'tfidf__max_df': (0.25),\n",
        "#     'tfidf__max_features': (100)\n",
        "   \n",
        "#     # 'clf__max_depth' :(3,5,8), \n",
        "#     # 'clf__reg_alpha': (1.0,0.5,0.1), \n",
        "#     # 'clf__subsample':(0.1,0.5,0.8), \n",
        "#     # 'clf__eta':(0.01,0.05,0.1)\n",
        "# }\n",
        "\n",
        "# grid_search_tune = GridSearchCV(pipeline, parameters, cv=20)\n",
        "# XGBoost = grid_search_tune.fit(X, Y)\n",
        "\n",
        "XGBoost = XGB_classifier.fit (X_train , Y )\n",
        "\n",
        "# print (grid_search_tune.best_estimator_.steps)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGd82eG1i4-p"
      },
      "source": [
        "\n",
        "X_test_vectorize  = vectorizer.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iSOxSuTnNtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77b5ef5-a909-4604-8fbc-c9ac315d2aa7"
      },
      "source": [
        "y_predict_XGBoost= XGBoost.predict(X_test_vectorize)\n",
        "\n",
        "\n",
        "print ('Accuracy for XGBoost: ',accuracy_score(Y_test, y_predict_XGBoost))\n",
        "print('F1-score for XGBoost: ', f1_score(Y_test, y_predict_XGBoost))\n",
        "print('roc_auc_score for XGBoost: ', roc_auc_score(Y_test, y_predict_XGBoost))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for XGBoost:  0.5332886933231299\n",
            "F1-score for XGBoost:  0.582955808188734\n",
            "roc_auc_score for XGBoost:  0.5326877324236479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkzSN11GmkVy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}