{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SheidaTalei_MeanShiftVsTFIDF_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+3MFoCr+VqMhK1nXq8nUp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SheidaTalei/FinalProject/blob/main/SheidaTalei_MeanShiftVsTFIDF_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqJC-wtgVKcI"
      },
      "source": [
        "\r\n",
        "#SUBJECT: Mean-shift Vs TF-IDF\r\n",
        "\r\n",
        "###AUTHOR: Sheida Talei"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-xyPuikU114",
        "outputId": "3d62e15c-1f49-4075-b840-74302d765d77"
      },
      "source": [
        "import os, sys\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "nb_path = '/content/notebooks'\r\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\r\n",
        "sys.path.insert(0,nb_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN14mQMAVZ_z"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.cluster import MeanShift , estimate_bandwidth"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5ISsbWVVZwz"
      },
      "source": [
        "#------------------------------------------Empty Rows Removal----------------------------------------------------------------\r\n",
        "# This function Will: 1- Remove all empty rows from csv file 2- Save data to the same csv\r\n",
        "def removeEmptyRows(fileName):\r\n",
        "    df = pd.read_csv(fileName, encoding='utf-8-sig')\r\n",
        "    df = df.dropna(subset=['text'], how='all', axis=0) \r\n",
        "    df.to_csv(fileName, header=True, encoding='utf-8-sig',  index=False)\r\n",
        "    \r\n",
        "    return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzVgc1NDVnHo"
      },
      "source": [
        "\r\n",
        "X_and_Y = removeEmptyRows ('/content/drive/MyDrive/Final/train_temp.csv')\r\n",
        "Y= X_and_Y.Label\r\n",
        "X = X_and_Y.text"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL7br5FSVnFY"
      },
      "source": [
        "#--------------------------------------------------Loading StopWords ------------------------------------------\r\n",
        "#Source of file: https://sites.google.com/site/kevinbouge/stopwords-lists\r\n",
        "def getStopWord ():\r\n",
        "    try:\r\n",
        "        file = open('/content/drive/MyDrive/Final/stopwords_fa.txt', 'r', encoding='utf-8-sig')\r\n",
        "        file_readed = file.read()\r\n",
        "    \r\n",
        "    finally:\r\n",
        "        file.close()\r\n",
        "        \r\n",
        "    stopWord_Set = set(file_readed.split())\r\n",
        "    return stopWord_Set"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQXJZJ5KVm8Q"
      },
      "source": [
        "persian_stop_word = list(getStopWord())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD4fUbjJVskn"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words= persian_stop_word ,  max_features = 2000 ) \r\n",
        "X_train_vector  = vectorizer.fit_transform(X)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0km2ejyVsdX"
      },
      "source": [
        "#source: https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/\r\n",
        "#source: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html\r\n",
        "#source: https://scikit-learn.org/stable/auto_examples/cluster/plot_mean_shift.html\r\n",
        "#If the chosen value is too big, then the clusters will tend to combine and the final output will be a smaller number of clusters than desired.\r\n",
        "# If the chosen value is too small, then the algorithm may produce too many clusters and it will take longer to run.\r\n",
        "\r\n",
        "#source:https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/generated/sklearn.cluster.estimate_bandwidth.html#sklearn.cluster.estimate_bandwidth\r\n",
        "bandwidth = estimate_bandwidth(X_train_vector.toarray(), quantile=0.2, n_samples=500)\r\n",
        "\r\n",
        "clustering = MeanShift(bandwidth=bandwidth)\r\n",
        "clustering.fit(X_train_vector.toarray())\r\n",
        "labels = clustering.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKDOKrPaZ5Y"
      },
      "source": [
        "labels = clustering.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkZUsOdyX-hp"
      },
      "source": [
        "cluster_centers = clustering.cluster_centers_\r\n",
        "print(cluster_centers)\r\n",
        "\r\n",
        "n_clusters_ = len(np.unique(labels))\r\n",
        "print(\"Number of estimated clusters:\", n_clusters_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpg6o4vMa_Q_"
      },
      "source": [
        "clustering.predict(X_train_vector)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}