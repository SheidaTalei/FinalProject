{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SheidaTalei_MeanShiftVsTFIDF_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMugDc7DdnPbzWJyU8xWrbX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SheidaTalei/FinalProject/blob/main/SheidaTalei_MeanShiftVsTFIDF_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqJC-wtgVKcI"
      },
      "source": [
        "\r\n",
        "#SUBJECT: Mean-shift Vs TF-IDF\r\n",
        "\r\n",
        "###AUTHOR: Sheida Talei"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-xyPuikU114",
        "outputId": "3bca92c8-c581-4895-adcd-d2bf9599424f"
      },
      "source": [
        "import os, sys\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "nb_path = '/content/notebooks'\r\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\r\n",
        "sys.path.insert(0,nb_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN14mQMAVZ_z"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.cluster import MeanShift , estimate_bandwidth\r\n",
        "from sklearn.decomposition import TruncatedSVD"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5ISsbWVVZwz"
      },
      "source": [
        "#------------------------------------------Empty Rows Removal----------------------------------------------------------------\r\n",
        "# This function Will: 1- Remove all empty rows from csv file 2- Save data to the same csv\r\n",
        "def removeEmptyRows(fileName):\r\n",
        "    df = pd.read_csv(fileName, encoding='utf-8-sig')\r\n",
        "    df = df.dropna(subset=['text'], how='all', axis=0) \r\n",
        "    df.to_csv(fileName, header=True, encoding='utf-8-sig',  index=False)\r\n",
        "    \r\n",
        "    return df"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzVgc1NDVnHo"
      },
      "source": [
        "\r\n",
        "X_and_Y = removeEmptyRows ('/content/drive/MyDrive/Final/train_temp.csv')\r\n",
        "Y= X_and_Y.Label\r\n",
        "X = X_and_Y.text"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL7br5FSVnFY"
      },
      "source": [
        "#--------------------------------------------------Loading StopWords ------------------------------------------\r\n",
        "#Source of file: https://sites.google.com/site/kevinbouge/stopwords-lists\r\n",
        "def getStopWord ():\r\n",
        "    try:\r\n",
        "        file = open('/content/drive/MyDrive/Final/stopwords_fa.txt', 'r', encoding='utf-8-sig')\r\n",
        "        file_readed = file.read()\r\n",
        "    \r\n",
        "    finally:\r\n",
        "        file.close()\r\n",
        "        \r\n",
        "    stopWord_Set = set(file_readed.split())\r\n",
        "    return stopWord_Set"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQXJZJ5KVm8Q"
      },
      "source": [
        "persian_stop_word = list(getStopWord())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD4fUbjJVskn"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words= persian_stop_word ,  max_features = 2000 ) \r\n",
        "X_train_vector  = vectorizer.fit_transform(X)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-INot6BqQw3"
      },
      "source": [
        "#source: https://stackoverflow.com/questions/34725726/is-it-possible-apply-pca-on-any-text-classification\r\n",
        "svd = TruncatedSVD(n_components=200)\r\n",
        "X_svd = svd.fit_transform(X_train_vector)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0km2ejyVsdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f55d48-d14a-4f99-df3a-cb0e453b0846"
      },
      "source": [
        "#source: https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/\r\n",
        "#source: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html\r\n",
        "#source: https://scikit-learn.org/stable/auto_examples/cluster/plot_mean_shift.html\r\n",
        "#If the chosen value is too big, then the clusters will tend to combine and the final output will be a smaller number of clusters than desired.\r\n",
        "# If the chosen value is too small, then the algorithm may produce too many clusters and it will take longer to run.\r\n",
        "\r\n",
        "#source:https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/generated/sklearn.cluster.estimate_bandwidth.html#sklearn.cluster.estimate_bandwidth\r\n",
        "# bandwidth = estimate_bandwidth(X_train_vector.toarray(), quantile=0.2, n_samples=500)\r\n",
        "\r\n",
        "clustering = MeanShift()\r\n",
        "clustering.fit(X_svd)\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MeanShift()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-L0iZRtd3V1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3b601a-c1f2-4d24-a856-d7df37f282ca"
      },
      "source": [
        "labels = clustering.labels_\r\n",
        "silhouette_score = metrics.silhouette_score(X_svd, labels, metric='euclidean')\r\n",
        "print (\"Silhouette_score: \",silhouette_score )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Silhouette_score:  0.2329766821465387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzVj--DkeOOk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJDJHZ3aeOIY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDa5Y3kceOGA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKDOKrPaZ5Y"
      },
      "source": [
        "labels = clustering.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkZUsOdyX-hp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1785a5f1-c361-40dc-f71a-b7e1bd60b1eb"
      },
      "source": [
        "cluster_centers = clustering.cluster_centers_\r\n",
        "print(cluster_centers)\r\n",
        "\r\n",
        "n_clusters_ = len(np.unique(labels))\r\n",
        "print(\"Number of estimated clusters:\", n_clusters_)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.00333170e-01 -7.25785044e-03 -1.35548383e-02 ...  1.22845164e-04\n",
            "   4.40775048e-04 -8.13436151e-04]\n",
            " [ 1.98905879e-01 -5.91866018e-01  7.06882866e-01 ...  1.64381933e-03\n",
            "  -4.47896326e-04 -2.53790521e-03]\n",
            " [ 1.57777607e-01 -1.29664684e-01 -1.24629711e-01 ... -4.40957356e-03\n",
            "   9.11103327e-03  9.11334543e-03]\n",
            " ...\n",
            " [ 2.31452596e-01 -1.22347239e-01 -6.88847221e-02 ...  2.06543181e-02\n",
            "   1.50130055e-02 -4.83537334e-02]\n",
            " [ 1.87093464e-01  2.16132758e-02 -7.10440670e-02 ... -4.37770365e-04\n",
            "  -1.06578074e-02 -5.63705324e-03]\n",
            " [ 1.66176610e-01  1.36658462e-02 -7.05808728e-02 ... -2.79859033e-03\n",
            "  -1.94851950e-02  7.37642597e-03]]\n",
            "Number of estimated clusters: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpg6o4vMa_Q_"
      },
      "source": [
        "# clustering.predict(X_train_vector)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYJwXehAn1MD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}