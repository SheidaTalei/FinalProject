{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SheidaTalei_MeanShiftvsBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcxn9sjgbvLGHiO+ktIbEo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SheidaTalei/FinalProject/blob/main/SheidaTalei_MeanShiftvsBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1jtHtQxO9KG"
      },
      "source": [
        "#SUBJECT: Mean Shift Vs BERT Embedding\r\n",
        "\r\n",
        "###AUTHOR: Sheida Talei"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YLlwiQIPFxa",
        "outputId": "8d0f888c-b547-47d3-bd8f-c3096faab18d"
      },
      "source": [
        "import os, sys\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "nb_path = '/content/notebooks'\r\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\r\n",
        "sys.path.insert(0,nb_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z08Ir6kKPKp_"
      },
      "source": [
        "import transformers\r\n",
        "from transformers import BertModel, BertTokenizer\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhQu5t8mPKni"
      },
      "source": [
        "\r\n",
        "\r\n",
        "#Convert a collection of raw documents to a matrix of TF-IDF features.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "# from transformers import TFBertModel, TFBertPreTrainedModel, TFBertForSequenceClassification\r\n",
        "# from transformers import glue_convert_examples_to_features, InputExample\r\n",
        "from sentence_transformers import SentenceTransformer\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.cluster import MeanShift , estimate_bandwidth\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns; sns.set()  # for plot styling\r\n",
        "# from kneed import KneeLocator\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTCFgm7SPKlg"
      },
      "source": [
        "#------------------------------------------Empty Rows Removal----------------------------------------------------------------\r\n",
        "# This function Will: 1- Remove all empty rows from csv file 2- Save data to the same csv\r\n",
        "def removeEmptyRows(fileName):\r\n",
        "    df = pd.read_csv(fileName, encoding='utf-8-sig')\r\n",
        "    df = df.dropna(subset=['text'], how='all', axis=0) \r\n",
        "    df.to_csv(fileName, header=True, encoding='utf-8-sig',  index=False)\r\n",
        "    \r\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYcN8dgNPfay"
      },
      "source": [
        "X_and_Y = removeEmptyRows ('/content/drive/MyDrive/Final/train_temp.csv')\r\n",
        "Y_train= X_and_Y.Label\r\n",
        "X_train = X_and_Y.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8SCi4a1PhSF"
      },
      "source": [
        "model = SentenceTransformer('bert-base-multilingual-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgf1z5h1Pioe"
      },
      "source": [
        "#Source: https://github.com/UKPLab/sentence-transformers\r\n",
        "sentence_embeddings = model.encode(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuRIKBgBPmh4"
      },
      "source": [
        "clustering = MeanShift()\r\n",
        "clustering.fit(sentence_embeddings)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKucXuzrPvL_"
      },
      "source": [
        "labels = clustering.labels_\r\n",
        "silhouette_score = metrics.silhouette_score(sentence_embeddings, labels, metric='euclidean')\r\n",
        "print (\"Silhouette_score: \",silhouette_score )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}